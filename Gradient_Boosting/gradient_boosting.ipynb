{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparacion de los datos que se usaran\n",
    "\n",
    "#Apertura de archivo csv a un dataframe de pandas\n",
    "#revisar la ruta para tu caso particular\n",
    "ruta = \"c:\\\\Users\\\\jrgui\\\\Documents\\\\GitHub\\\\Machine_Learning\\\\Redes_Neuronales\\\\datasets\\\\Churn_Modelling.csv\"\n",
    "dataset = pd.read_csv(ruta)\n",
    "dataset.head(5)\n",
    "#Datos de los clintes de un banco, queremos entrenar una red que diga si el cliete se va o se queda\n",
    "\n",
    "# Preprocesado de datos\n",
    "from sklearn import preprocessing\n",
    "#Se escogen las variable dependiente e independientes\n",
    "X = dataset.iloc[:,3:13].values\n",
    "y = dataset.iloc[:,13].values\n",
    "\n",
    "#Transformar a variables categoricas ordinales\n",
    "labelencoder_x_paises = preprocessing.LabelEncoder()\n",
    "#cambio los nombre de los paises en categorias ordinales\n",
    "X[:,1] = labelencoder_x_paises.fit_transform(X[:,1])\n",
    "labelencoder_x_generos = preprocessing.LabelEncoder()\n",
    "#cambio los generos en categorias ordinales\n",
    "X[:,2] = labelencoder_x_generos.fit_transform(X[:,2])\n",
    "#Ahorra se debe pasar a variable dummy con onehotencoder\n",
    "#tranforma el arreglo en un arreglo de numpy\n",
    "data = np.array(X)\n",
    "# Separar la primera columna del resto\n",
    "paises_column = data[:, 1].reshape(-1, 1)\n",
    "generos_column = data[:, 2].reshape(-1, 1)\n",
    "demas_columns = data[:, 3:]\n",
    "primera_columns = data[:, 0].reshape(-1, 1)\n",
    "\n",
    "# Crear el codificador OneHotEncoder\n",
    "encoder_paises = preprocessing.OneHotEncoder(sparse_output=False)\n",
    "encoder_generos = preprocessing.OneHotEncoder(sparse_output=False)\n",
    "# Ajustar y transformar la primera columna\n",
    "paises_column_encoded = encoder_paises.fit_transform(paises_column)\n",
    "generos_column_encoded = encoder_paises.fit_transform(generos_column)\n",
    "# Concatenar la columna codificada con las demÃ¡s columnas\n",
    "X = np.hstack((paises_column_encoded, primera_columns, generos_column_encoded, demas_columns))\n",
    "#para evitar la colinealidad se deben eliminar 2 columnas una de paises y una de generos\n",
    "X = np.delete(X, (0,4), axis=1)\n",
    "#Division de Datos - entrenamiento y validacion\n",
    "#herramienta para dividir los datos\n",
    "from sklearn.model_selection import train_test_split\n",
    "#divide los datos en 20% para la validacion y se colocar una semilla para hacer la division\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=0)\n",
    "\n",
    "#No es necesario estandarizar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1494,  101],\n",
       "       [ 193,  212]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Algoritmo de Gradient Boosting\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#juste de Gradient Boosting\n",
    "clasificador = XGBClassifier()\n",
    "clasificador.fit(X_train,y_train)\n",
    "\n",
    "#Predicciones\n",
    "y_pred = clasificador.predict(X_test)\n",
    "y_pred = (y_pred>0.5)\n",
    "\n",
    "#Matriz de confusion\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promedio de Precision Global 0.8515\n",
      "Desviacion Estandar de las Precisiones 0.009516433155337116\n"
     ]
    }
   ],
   "source": [
    "#Prueba de validacion cruzada\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = clasificador, X = X_train, y = y_train, cv = 10)\n",
    "print(\"Promedio de Precision Global\",accuracies.mean())\n",
    "print(\"Desviacion Estandar de las Precisiones\",accuracies.std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
