En construccion 
<p align="center">
<img src="images/banner.png"  height=400>
</p>

# ndice

* [Pre Procesamiento](#Pre-Procesamiento) 

* [Regresi贸n](#Regresi贸n) 
 * [Regresi贸n Lineal Simple](#Regresi贸n-Lineal-Simple) 
 * [Regresi贸n Lineal M煤ltiple](#Regresi贸n-Lineal-M煤ltiple) 
 * [Regresi贸n Lineal Polin贸mica](#Regresi贸n-Lineal-Polin贸mica) 
 * [Support Vector Machine (SVM)](#Support-Vector-Machine-(SVM)) 
 * [Decision Tree](#Decision-Tree) 
 * [Random Forest](#Random-Forest) 

* [Clasificaci贸n](#Clasificaci贸n) 
* [Agrupamiento](#Agrupamiento) 
* [Reglas de Asociaci贸n](#Reglas-de-Asociaci贸n) 
* [Aprendizaje por Refuerzo](#Aprendizaje-por-Refuerzo) 
* [Procesamiento de Lenguaje Natural](#Procesamiento-de-Lenguaje-Natural) 
* [Redes Neuronales](#Redes-Neuronales) 
* [Reducci贸n de Dimensiones](#Redes-Neuronales) 
* [Selecci贸n de Modelos](#Seleccion-de-Modelos) 
* [Gradient Boosting](#Gradient-Boosting) 

* [Autor](#Autor)

*NOTA:* Se us贸 rutas absolutas por lo que debes verificar el patch que usar谩s al correr los c贸digos.

# [Pre Procesamiento](https://github.com/jrguignan/Machine_Learning/tree/main/Pre_Procesamiento)

[Preprocesamietno-Python](https://github.com/jrguignan/Machine_Learning/blob/main/Pre_Procesamiento/pre_procesamiento.ipynb) - [Preprocesamietno-R](https://github.com/jrguignan/Machine_Learning/blob/main/Pre_Procesamiento/pre_procesamiento.R)

El preprocesamiento de datos es una etapa crucial en el flujo de trabajo de machine learning que involucra la limpieza y transformaci贸n de datos brutos para prepararlos para el an谩lisis y modelado. La importancia del preprocesamiento radica en su capacidad para mejorar la calidad y la utilidad de los datos, lo cual es fundamental para el rendimiento y la precisi贸n de los modelos de machine learning. Datos bien preprocesados pueden reducir el ruido, manejar la multicolinealidad y garantizar que los algoritmos de aprendizaje funcionen de manera m谩s eficiente y efectiva, conduciendo a modelos m谩s robustos y resultados m谩s confiables.

En esta secci贸n se revisar谩n varios de los factores a tener en cuenta.

- Datos Faltantes
- Tratamiento de variables
- Normalizaci贸n y escalado de Datos
- Divisi贸n de Datos

<br>[Volver al ndice](#ndice)

# [Regresi贸n](https://github.com/jrguignan/Machine_Learning/tree/main/Regresion)

Para poder aplicar un modelo de regresi贸n lineal se debe tener en cuenta:
- Linealidad
- Homocedasticidad
- Normalidad Multivariable
- Independencia de los Errores
- Ausencia de Multicolinealidad


## Regresi贸n Lineal Simple

[Regresion Lineal Simple-Python](https://github.com/jrguignan/Machine_Learning/blob/main/Regresion/regresion_lineal_simple.ipynb) - [Regresion Lineal Simple-R](https://github.com/jrguignan/Machine_Learning/blob/main/Regresion/regresion_lineal_simple.R)

El modelo de regresi贸n lineal simple es una t茅cnica estad铆stica utilizada para predecir el valor de una variable dependiente bas谩ndose en el valor de una variable independiente. Este modelo asume una relaci贸n lineal entre las dos variables y se representa con la ecuaci贸n y=mx+b, donde y es la variable dependiente, x es la variable independiente, m es la pendiente de la l铆nea y b es la intersecci贸n en el eje y. La importancia de los modelos de regresi贸n lineal simple radica en su capacidad para identificar y cuantificar relaciones entre variables, permitiendo predicciones y an谩lisis de tendencias en una variedad de campos como la econom铆a, la biolog铆a y la ingenier铆a. Adem谩s, su simplicidad y facilidad de interpretaci贸n lo convierten en una herramienta fundamental y accesible para el an谩lisis de datos y la toma de decisiones basada en evidencia.

## Regresi贸n Lineal M煤ltiple

[Regresion Lineal M煤ltiple-Python](https://github.com/jrguignan/Machine_Learning/blob/main/Regresion/regresion_lineal_multiple.ipynb) - [Regresion Lineal M煤ltiple-R](https://github.com/jrguignan/Machine_Learning/blob/main/Regresion/regresion_lineal_multiple.R)

El modelo de regresi贸n lineal m煤ltiple es una extensi贸n de la regresi贸n lineal simple que permite predecir el valor de una variable dependiente bas谩ndose en m煤ltiples variables independientes. Representado por la ecuaci贸n =0+11+22+...+ヰ , donde  es la variable dependiente y 1,2,...,ヰ son las variables independientes, este modelo captura la relaci贸n conjunta entre varias variables y su impacto en el resultado. La importancia de los modelos de regresi贸n lineal m煤ltiple radica en su capacidad para manejar situaciones m谩s complejas y realistas donde m煤ltiples factores influyen en el resultado, proporcionando un an谩lisis m谩s robusto y preciso. Esta t茅cnica es crucial en campos como la econom铆a, el marketing, la medicina y las ciencias sociales, donde se requiere comprender y predecir resultados basados en m煤ltiples influencias simult谩neamente

M茅todo de cosntruccion del modelo final:
- Exahustivo (all in)
- Eliminaci贸n hacia atr谩s
- Selecci贸n hacia adelante
- Eliminaci贸n Bilateral
- Comparaci贸n de scores

Estos m茅todos de construccion permiten ir ajustando el modelo a las variables independiente que nos pueden producir un mejor resultado. 

## Regresi贸n Lineal Polin贸mica

[Regresion Lineal Polin贸mica-Python](https://github.com/jrguignan/Machine_Learning/blob/main/Regresion/regresion_lineal_polinomica.ipynb) - [Regresion Lineal Polin贸mica-R](https://github.com/jrguignan/Machine_Learning/blob/main/Regresion/regresion_lineal_polinomica.R)


El modelo de regresi贸n lineal polin贸mica es una variante de la regresi贸n lineal que permite capturar relaciones no lineales entre las variables independientes y la variable dependiente al incluir t茅rminos polin贸micos (cuadr谩ticos, c煤bicos, etc.) de las variables independientes. Representado por la ecuaci贸n 
=0+1+2^2+...+^, este modelo es importante porque proporciona una mayor flexibilidad para ajustar y predecir datos que no siguen una tendencia lineal, mejorando as铆 la precisi贸n y el ajuste del modelo. 

## Support Vector Machine (SVM)

[Support Vector Machine-Python](https://github.com/jrguignan/Machine_Learning/blob/main/Regresion/regresion_SVM.ipynb) - [Support Vector Machine-R](https://github.com/jrguignan/Machine_Learning/blob/main/Regresion/regresion_SVM.R)


Los modelos de Support Vector Machine (SVM) en regresi贸n, conocidos como Support Vector Regression (SVR), son una t茅cnica que busca encontrar la funci贸n que devuelva el m铆nimo error posible, manteniendo un margen de tolerancia . SVR utiliza un enfoque similar al de clasificaci贸n SVM, creando un tubo alrededor de la funci贸n objetivo donde las desviaciones menores a  no se consideran como errores. La importancia de SVR radica en su capacidad para manejar grandes cantidades de datos y su eficacia en problemas de alta dimensionalidad. Adem谩s, SVR es robusto ante outliers y es capaz de modelar relaciones complejas no lineales mediante el uso de kernels, lo que lo convierte en una herramienta poderosa para tareas de predicci贸n.

## Decision Tree

[Decision Tree-Python](https://github.com/jrguignan/Machine_Learning/blob/main/Regresion/regresion_arboles_decision.ipynb) - [Decision Tree-R](https://github.com/jrguignan/Machine_Learning/blob/main/Regresion/regresion_arboles_decision.R)

Los modelos de Decision Tree en regresi贸n son m茅todos no param茅tricos que dividen los datos en segmentos bas谩ndose en valores de caracter铆sticas, creando un 谩rbol de decisiones donde cada hoja representa un valor de predicci贸n. Cada nodo en el 谩rbol divide los datos en subconjuntos m谩s homog茅neos en cuanto a la variable objetivo. La importancia de los Decision Trees en regresi贸n radica en su simplicidad, interpretabilidad y capacidad para capturar relaciones no lineales y complejas entre las caracter铆sticas y la variable objetivo. Son robustos ante datos faltantes y permiten la incorporaci贸n de caracter铆sticas categ贸ricas sin necesidad de codificaci贸n. Adem谩s, al ser la base de m茅todos avanzados como Random Forest y Gradient Boosting, los Decision Trees son fundamentales para mejorar la precisi贸n y reducir el sobreajuste en los modelos predictivos.

## Random Forest

[Random Forest-Python](https://github.com/jrguignan/Machine_Learning/blob/main/Regresion/regresion_bosques_aleatorios.ipynb) - [Random Forest-R](https://github.com/jrguignan/Machine_Learning/blob/main/Regresion/regresion_bosques_aleatorios.R)

Un modelo de regresi贸n de Random Forest es una t茅cnica de aprendizaje autom谩tico que utiliza m煤ltiples 谩rboles de decisi贸n para realizar predicciones m谩s precisas. Este m茅todo consiste en construir numerosos 谩rboles de decisi贸n en el proceso de entrenamiento y obtener el promedio de sus predicciones para la regresi贸n. La importancia de los modelos de Random Forest radica en su capacidad para manejar grandes cantidades de datos y caracter铆sticas sin requerir demasiada preparaci贸n de datos. Adem谩s, son robustos frente al sobreajuste, ya que la combinaci贸n de m煤ltiples 谩rboles de decisi贸n reduce la varianza del modelo, proporcionando resultados m谩s confiables y estables.

<br>[Volver al ndice](#ndice)

# [Clasificaci贸n](https://github.com/jrguignan/Machine_Learning/tree/main/Clasificacion)

## Regresi贸n Log铆stica

## K Vecinos Cercanos

## Maquinas de Soporte Vectorial

## Naive Bayes

## rboles de Desici贸n

## Bosque Aleatorio

<br>[Volver al ndice](#ndice)

# [Agrupamiento](https://github.com/jrguignan/Machine_Learning/tree/main/Agrupamiento)

## K Medias

La trampa de inicializaci贸n se resuelve con k-means++

### WCSS - M茅todo del Codo

## Agrupamiento Jerarquico

<br>[Volver al ndice](#ndice)

# [Reglas de Asociaci贸n](https://github.com/jrguignan/Machine_Learning/tree/main/Reglas_de_Asociacion)


## A Priori

## Eclat

<br>[Volver al ndice](#ndice)

# [Aprendizaje por Refuerzo](https://github.com/jrguignan/Machine_Learning/tree/main/Aprendizaje_por_Refuerzo)

## L铆mite Superior de Confianza

## Muestreo Thompson

<br>[Volver al ndice](#ndice)

# [Procesamiento de Lenguaje Natural](https://github.com/jrguignan/Machine_Learning/tree/main/Procesamiento_de_Lenguaje_Natural)


<br>[Volver al ndice](#ndice)

# [Redes Neuronales](https://github.com/jrguignan/Machine_Learning/tree/main/Redes_Neuronales)

## Redes Neuronales Artificiales

## Redes Neuronales Convolucionales

Al ser el dataset un poco pesado se puede descargar de este link:
[dataset-RNC](https://drive.google.com/file/d/1Kay-Ig6g2EyDBKPK0oK4UmGj8fCcifpb/view?usp=sharing)

<br>[Volver al ndice](#ndice)

# [Reducci贸n de Dimensiones](https://github.com/jrguignan/Machine_Learning/tree/main/Reduccion_de_Dimension)

## An谩lisis de Componentes Principales

## An谩lisis Discriminate Lineal

## An谩lisis de Componentes Principales - Kernel

<br>[Volver al ndice](#ndice)

# [Selecci贸n de Modelos](https://github.com/jrguignan/Machine_Learning/tree/main/Seleccion_de_Modelos)


## K Partes Validaci贸n Cruzada

## Busqueda de Rejilla


<br>[Volver al ndice](#ndice)

# [Gradient Boosting](https://github.com/jrguignan/Machine_Learning/tree/main/Gradient_Boosting)

<br>[Volver al ndice](#ndice)

# Autor

- Jos茅 R. Guignan
- Mail: joserguignan@gmail.com
- Linkedin: [https://www.linkedin.com/in/jrguignan](https://www.linkedin.com/in/jrguignan)
